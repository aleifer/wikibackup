This is a simple set of wikibackupscripts. It is designed to work with turnkey linux's mediawiki. It was written for mediawiki 1.14. 

It does SQL dump, an XML dump and it copies over the supporting files. It auto tar gzips them. 

If there are more than a specified number of files in the target directory it will toss out a specified number of the  oldest backups. This way you have a rolling backup, with a bunch of timestamps but it doesn't overflow.

Here is the output of, "sudo crontab -e":
58 22 * * * /home/andy/WikiScripts/wikiBackup /mnt/usbHD/wikiBackup/Daily/
58 4 1 * * /home/andy/WikiScripts/wikiBackup /mnt/usbHD/wikiBackup/Monthly/
58 23 * * *  /usr/bin/php /usr/share/mediawiki/maintenance/DumpHTML/dumpHTML.php -d ~/mnt/usbHD/staticDump -k monobook --image-snapshot --force-copy


Remember: samulelabisawesome!!!